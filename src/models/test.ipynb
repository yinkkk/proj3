{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('D:\\\\Project\\\\DeepLearning\\\\proj3\\\\data\\\\train.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# D:\\Project\\DeepLearning\\proj3\\src\\engine\\train.py\n",
    "# ==============================================\n",
    "import os,sys\n",
    "import torch\n",
    "import timm\n",
    "import tqdm\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ---------- 1. 以“本文件”为锚点，一次性算出根目录 ----------\n",
    "FILE_ROOT = pathlib.Path(__file__).resolve()          # 当前文件\n",
    "SRC_DIR   = FILE_ROOT.parent                          # ...\\src\\engine\n",
    "PROJ_ROOT = SRC_DIR.parent.parent                     # ...\\proj3\n",
    "\n",
    "# ---------- 2. 所有路径全部用 Path，拼出来 ----------\n",
    "CSV_TRAIN = PROJ_ROOT / 'data' / 'train.csv'\n",
    "CSV_VAL   = PROJ_ROOT / 'data' / 'val.csv'\n",
    "IMG_DIR   = PROJ_ROOT / 'data' / 'images'\n",
    "CKPT_DIR  = PROJ_ROOT / 'experiments' / 'vit_baseline'\n",
    "\n",
    "# 如果 experiments 下还有子目录，也一次性建好\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- 3. 把项目根目录加入 PYTHONPATH，避免 import 报错 ----------\n",
    "sys.path.insert(0, str(PROJ_ROOT))\n",
    "\n",
    "# ---------- 4. 正常 import 你自己的模块 ----------\n",
    "from src.data.dataset import FundusDataset\n",
    "from src.models.vit import get_model\n",
    "from src.losses import FocalBCELoss\n",
    "from src.metrics import MetricTracker\n",
    "from src.utils.seed import seed_everything\n",
    "\n",
    "# ===============================\n",
    "# 超参数\n",
    "# ===============================\n",
    "cfg = {\n",
    "    # === data ===\n",
    "    \"img_size\": 224,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 8,\n",
    "    \"n_classes\": 20,\n",
    "\n",
    "    # === model ===\n",
    "    \"arch\": \"vit_base_patch16_224\",\n",
    "    \"pretrained\": True,\n",
    "    \"drop_rate\": 0.1,\n",
    "\n",
    "    # === optimizer ===\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"scheduler\": \"cosine\",\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"epochs\": 30,\n",
    "\n",
    "    # === loss ===\n",
    "    \"loss_name\": \"focal\",\n",
    "    \"focal_gamma\": 2.0,\n",
    "    \"focal_alpha\": None,\n",
    "\n",
    "    # === misc ===\n",
    "    \"seed\": 23,\n",
    "    \"ckpt_dir\": CKPT_DIR,          # 直接用上面算好的路径\n",
    "    \"resume\": None\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# 训练主函数\n",
    "# ===============================\n",
    "def run(cfg):\n",
    "    seed_everything(cfg['seed'])\n",
    "    os.makedirs(cfg['ckpt_dir'], exist_ok=True)\n",
    "\n",
    "    # ---- 数据 ----\n",
    "    train_set = FundusDataset(CSV_TRAIN, IMG_DIR, img_size=224, mode='train')\n",
    "    val_set   = FundusDataset(CSV_VAL,   IMG_DIR, img_size=224, mode='val')\n",
    "    train_loader = DataLoader(train_set, cfg['batch_size'], shuffle=True,\n",
    "                              num_workers=cfg['num_workers'], pin_memory=True)\n",
    "    val_loader   = DataLoader(val_set,   cfg['batch_size'], shuffle=False,\n",
    "                              num_workers=cfg['num_workers'], pin_memory=True)\n",
    "\n",
    "    # ---- 模型 ----\n",
    "    model = get_model(cfg['arch'], cfg['n_classes'],\n",
    "                      pretrained=cfg['pretrained'],\n",
    "                      drop_rate=cfg['drop_rate']).cuda()\n",
    "\n",
    "    # ---- 损失 ----\n",
    "    if cfg['loss_name'].lower() == 'focal':\n",
    "        criterion = FocalBCELoss(alpha=None, gamma=cfg['focal_gamma']).cuda()\n",
    "    else:\n",
    "        criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    # ---- 优化器 & 调度器 ----\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                  lr=cfg['lr'],\n",
    "                                  weight_decay=cfg['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=cfg['epochs'])\n",
    "\n",
    "    # ---- 训练循环 ----\n",
    "    best_auc = 0.\n",
    "    for epoch in range(1, cfg['epochs'] + 1):\n",
    "        # --- train ---\n",
    "        model.train()\n",
    "        for x, y in tqdm.tqdm(train_loader, desc=f'Epoch {epoch} [Train]'):\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # --- val ---\n",
    "        model.eval()\n",
    "        metric = MetricTracker(cfg['n_classes'])\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm.tqdm(val_loader, desc=f'Epoch {epoch} [Val]'):\n",
    "                x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "                logits = model(x)\n",
    "                metric.update(logits, y)\n",
    "        val_dict = metric.compute()\n",
    "        print(f'Epoch {epoch:02d} | val_auc={val_dict[\"auc\"]:.4f}')\n",
    "\n",
    "        # --- save best ---\n",
    "        if val_dict['auc'] > best_auc:\n",
    "            best_auc = val_dict['auc']\n",
    "            save_path = cfg['ckpt_dir'] / 'best_auc.pth'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'✅ Saved new best model (AUC={best_auc:.4f}) -> {save_path}')\n",
    "\n",
    "# ---------- 启动 ----------\n",
    "if __name__ == '__main__':\n",
    "    run(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9ee94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   0%|          | 0/56 [00:00<?, ?it/s]c:\\Users\\Yqj\\anaconda3\\envs\\new_env\\lib\\site-packages\\timm\\layers\\attention.py:80: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  x = F.scaled_dot_product_attention(\n",
      "Epoch 1 [Train]:  11%|█         | 6/56 [01:33<12:57, 15.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 188\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 133\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m    131\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    132\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 133\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    134\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# ===== val =====\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "class FundusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, img_dir, img_size=224, mode='train'):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.img_size = img_size\n",
    "        self.mode = mode\n",
    "\n",
    "        self.label_cols = self.df.columns[1:]  # 第一列 path，其余列为标签\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.aug = A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.RandomBrightnessContrast(0.2, 0.2, p=0.5),\n",
    "                A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        else:\n",
    "            self.aug = A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.img_dir / row['path']  # 根据你的列名\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.aug(image=image)['image']\n",
    "\n",
    "        if self.mode in ['train', 'val']:\n",
    "            label = torch.tensor(row[self.label_cols].astype(float).values, dtype=torch.float32)\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, row['path']\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Focal BCE Loss\n",
    "# -----------------------------\n",
    "class FocalBCELoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = torch.tensor(alpha, dtype=torch.float32) if alpha is not None else None\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(logits, target, reduction='none')\n",
    "        p = torch.sigmoid(logits)\n",
    "        pt = p * target + (1 - p) * (1 - target)\n",
    "        focal_factor = (1 - pt) ** self.gamma\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            alpha_factor = self.alpha * target + (1 - self.alpha) * (1 - target)\n",
    "            loss = alpha_factor * focal_factor * bce_loss\n",
    "        else:\n",
    "            loss = focal_factor * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "import timm\n",
    "def get_model(arch='vit_base_patch16_224', n_classes=20, pretrained=True, drop_rate=0.1):\n",
    "    model = timm.create_model(arch, pretrained=pretrained, num_classes=n_classes, drop_rate=drop_rate)\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    y_pred_label = (torch.sigmoid(y_pred) > 0.5).float()\n",
    "    auc = roc_auc_score(y_true.cpu().numpy(), torch.sigmoid(y_pred).cpu().numpy(), average='macro')\n",
    "    f1 = f1_score(y_true.cpu().numpy(), y_pred_label.cpu().numpy(), average='macro')\n",
    "    acc = accuracy_score(y_true.cpu().numpy(), y_pred_label.cpu().numpy())\n",
    "    return {'auc': auc, 'f1': f1, 'acc': acc}\n",
    "\n",
    "# -----------------------------\n",
    "# Training loop\n",
    "# -----------------------------\n",
    "def train(cfg):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    os.makedirs(cfg['ckpt_dir'], exist_ok=True)\n",
    "\n",
    "    train_set = FundusDataset(cfg['train_csv'], cfg['img_dir'], cfg['img_size'], mode='train')\n",
    "    val_set   = FundusDataset(cfg['val_csv'],   cfg['img_dir'], cfg['img_size'], mode='val')\n",
    "    train_loader = DataLoader(train_set, batch_size=cfg['batch_size'], shuffle=True, num_workers=cfg['num_workers'])\n",
    "    val_loader   = DataLoader(val_set,   batch_size=cfg['batch_size'], shuffle=False, num_workers=cfg['num_workers'])\n",
    "\n",
    "    model = get_model(cfg['arch'], cfg['n_classes'], cfg['pretrained'], cfg['drop_rate']).to(device)\n",
    "    criterion = FocalBCELoss(gamma=cfg['focal_gamma']).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg['epochs'])\n",
    "\n",
    "    best_auc = 0\n",
    "    for epoch in range(1, cfg['epochs']+1):\n",
    "        # ===== train =====\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in tqdm(train_loader, desc=f'Epoch {epoch} [Train]'):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # ===== val =====\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        y_true_list = []\n",
    "        y_pred_list = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "                y_true_list.append(y)\n",
    "                y_pred_list.append(logits)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        y_true = torch.cat(y_true_list, dim=0)\n",
    "        y_pred = torch.cat(y_pred_list, dim=0)\n",
    "        metrics = compute_metrics(y_true, y_pred)\n",
    "\n",
    "        print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n",
    "              f\"val_auc={metrics['auc']:.4f}, val_f1={metrics['f1']:.4f}, val_acc={metrics['acc']:.4f}\")\n",
    "\n",
    "        # ===== save best model =====\n",
    "        if metrics['auc'] > best_auc:\n",
    "            best_auc = metrics['auc']\n",
    "            torch.save(model.state_dict(), os.path.join(cfg['ckpt_dir'], 'best_model.pth'))\n",
    "            print(f\"Saved best model at epoch {epoch} with AUC={best_auc:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "cfg = {\n",
    "    'train_csv': 'D:\\\\Project\\\\DeepLearning\\\\proj3\\\\data\\\\train.csv',\n",
    "    'val_csv': 'D:\\\\Project\\\\DeepLearning\\\\proj3\\\\data\\\\val.csv',\n",
    "    'img_dir': 'D:\\\\Project\\\\DeepLearning\\\\proj3\\\\data\\\\images',\n",
    "    'img_size': 224,\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 0,\n",
    "    'n_classes': 20,\n",
    "    'arch': 'vit_base_patch16_224',\n",
    "    'pretrained': True,\n",
    "    'drop_rate': 0.1,\n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'epochs': 30,\n",
    "    'focal_gamma': 2.0,\n",
    "    'ckpt_dir': 'experiments/vit_bce_focal'\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Run\n",
    "# -----------------------------\n",
    "if __name__ == '__main__':\n",
    "    train(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
